{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TP 2 : tokenisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify header names\n",
    "header = ['ID', 'ID_bis', 'col_1', 'col_2', 'col_3', 'text']\n",
    "# Load CSV file into a DataFrame\n",
    "df = pd.read_csv(r'../juritok/jorf_2023.csv', sep='|', header=None, names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_bis</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>fr/lr/loi/2023-1380/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFVERS000048734585</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>LOI n° 2023-1380 du 30 décembre 2023 visant à ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I. — Après l'article L. 2122-19 du code généra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>« Art. L. 2122-19-1. — Pour assurer les foncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>II. — L'article L. 2122-19-1 du code général d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                ID_bis  col_1 col_2  col_3  \\\n",
       "0  JORFTEXT000048734585                   NaN      0   NaN      0   \n",
       "1  JORFTEXT000048734585  JORFVERS000048734585      0   NaN      0   \n",
       "2  JORFTEXT000048734585  JORFARTI000048734586      1     1      1   \n",
       "3  JORFTEXT000048734585  JORFARTI000048734586      1     1      2   \n",
       "4  JORFTEXT000048734585  JORFARTI000048734586      1     1      3   \n",
       "\n",
       "                                                text  \n",
       "0                     fr/lr/loi/2023-1380/2023-12-31  \n",
       "1  LOI n° 2023-1380 du 30 décembre 2023 visant à ...  \n",
       "2  I. — Après l'article L. 2122-19 du code généra...  \n",
       "3  « Art. L. 2122-19-1. — Pour assurer les foncti...  \n",
       "4  II. — L'article L. 2122-19-1 du code général d...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the test sample input for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokenized texts from the last column\n",
    "test_sample = 0.1\n",
    "tokenized_texts = df['text'].tolist()[:int(len(df)*test_sample)]\n",
    "\n",
    "\n",
    "# Define the output txt file path\n",
    "txt_file_path = r'/Users/lbeauval/Desktop/Mines/3A/NLP/TP_2/juritok/text.txt'\n",
    "\n",
    "# Write the tokenized texts to the txt file\n",
    "with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "    for text in tokenized_texts:\n",
    "        txt_file.write(text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/Users/lbeauval/Desktop/Mines/3A/NLP/TP_2/juritok/text.txt --model_prefix=jorf --vocab_size=1000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /Users/lbeauval/Desktop/Mines/3A/NLP/TP_2/juritok/text.txt\n",
      "  input_format: \n",
      "  model_prefix: jorf\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: /Users/lbeauval/Desktop/Mines/3A/NLP/TP_2/juritok/text.txt\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 45431 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=6879391\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9526% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=91\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999526\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 45431 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=4495907\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 89949 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 45431\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 51660\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 51660 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=34471 obj=11.402 num_tokens=124715 num_tokens/piece=3.61797\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=28927 obj=8.7369 num_tokens=125177 num_tokens/piece=4.32734\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=21679 obj=8.72836 num_tokens=131664 num_tokens/piece=6.07334\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=21648 obj=8.71132 num_tokens=131689 num_tokens/piece=6.08319\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=16235 obj=8.79402 num_tokens=142241 num_tokens/piece=8.76138\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=16235 obj=8.77295 num_tokens=142304 num_tokens/piece=8.76526\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12176 obj=8.88884 num_tokens=154854 num_tokens/piece=12.718\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=12175 obj=8.8645 num_tokens=154852 num_tokens/piece=12.7189\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=9131 obj=9.02352 num_tokens=168852 num_tokens/piece=18.4922\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=9131 obj=8.99211 num_tokens=168853 num_tokens/piece=18.4923\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=6848 obj=9.1981 num_tokens=183553 num_tokens/piece=26.8039\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=6848 obj=9.15855 num_tokens=183554 num_tokens/piece=26.804\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5136 obj=9.444 num_tokens=199057 num_tokens/piece=38.7572\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5136 obj=9.39491 num_tokens=199069 num_tokens/piece=38.7595\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3852 obj=9.72723 num_tokens=214195 num_tokens/piece=55.6062\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3852 obj=9.66749 num_tokens=214196 num_tokens/piece=55.6064\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2889 obj=10.0611 num_tokens=230016 num_tokens/piece=79.6179\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2889 obj=9.99068 num_tokens=230733 num_tokens/piece=79.866\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2166 obj=10.4619 num_tokens=247642 num_tokens/piece=114.331\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2166 obj=10.3792 num_tokens=247650 num_tokens/piece=114.335\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1624 obj=10.9492 num_tokens=263843 num_tokens/piece=162.465\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1624 obj=10.8548 num_tokens=263857 num_tokens/piece=162.474\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1218 obj=11.5049 num_tokens=280730 num_tokens/piece=230.484\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1218 obj=11.3993 num_tokens=280732 num_tokens/piece=230.486\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1100 obj=11.6435 num_tokens=288145 num_tokens/piece=261.95\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1100 obj=11.6053 num_tokens=288145 num_tokens/piece=261.95\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: jorf.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: jorf.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(f'--input={txt_file_path} --model_prefix=jorf --vocab_size=1000')\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('jorf.model')\n",
    "\n",
    "tokens = sp.encode_as_pieces(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Art', '.', '▁R', '.', '▁', '22', '8', '-1', '.', '▁', '—', '▁Les', '▁', 'j', 'ur', 'is', 'te', 's', '▁a', 's', 's', 'is', 't', 'ant', 's', '▁re', 'c', 'r', 'ut', 'és', '▁en', '▁application', '▁de', '▁l', \"'\", 'article', '▁L', '.', '▁', '22', '8', '-1', '▁', 'ap', 'p', 'ort', 'ent', '▁leur', '▁concours', '▁à', '▁l', \"'\", 'analyse', '▁', 'j', 'ur', 'i', 'd', 'ique', '▁des', '▁dossier', 's', '▁n', 'éc', 'es', 's', 'it', 'ant', '▁une', '▁', 'expert', 'is', 'e', '▁par', 't', 'ic', 'ul', 'ière', '▁qui', '▁leur', '▁sont', '▁con', 'f', 'i', 'és', '▁par', '▁les', '▁m', 'ag', 'is', 't', 'r', 'at', 's', '▁sous', '▁la', '▁direction', '▁des', 'quel', 's', '▁', 'il', 's', '▁sont', '▁p', 'l', 'ac', 'és', '.', '▁Il', 's', '▁sont', '▁re', 'c', 'r', 'ut', 'és', '▁en', '▁qualité', '▁d', \"'\", 'ag', 'ent', '▁contractuel', '▁de', '▁l', \"'\", 'Etat', '▁relevant', '▁de', '▁la', '▁catégorie', '▁A', '.']\n",
      "[70, 108, 233, 847, 20, 4, 87, 690, 3, 338, 3, 64, 4, 566, 3, 5, 404, 33, 494, 5, 506, 3, 5, 212, 3, 40, 80, 48, 11, 116, 47, 39, 15, 83, 81, 17, 19, 22, 190, 100, 19, 332, 140, 778, 28, 16, 33, 91, 42, 39, 137, 109, 25, 171, 5, 12, 4, 19, 26, 74, 19, 153, 71, 94, 4, 426, 56, 82, 5, 12, 71, 152, 73, 31, 30, 81, 261, 18, 4, 566, 3, 846, 28, 59, 12, 802, 5, 8, 6, 672, 9]\n"
     ]
    }
   ],
   "source": [
    "# test encode\n",
    "\n",
    "pieces = sp.encode_as_pieces(\"Le présent arrêté fixe les prescriptions applicables aux installations de mise en œuvre de produits de préservation du bois et matériaux dérivés soumises à enregistrement au titre de la rubrique n° 2415 de la nomenclature des installations classées pour la protection de l'environnement.\")\n",
    "ids = sp.encode_as_ids(\"Le présent arrêté fixe les prescriptions applicables aux installations de mise en œuvre de produits de préservation du bois et matériaux dérivés soumises à enregistrement au titre de la rubrique n° 2415 de la nomenclature des installations classées pour la protection de l'environnement.\")\n",
    "print(sub_units)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le présent arrêté fixe les prescriptions applicables aux installations de mise en œuvre de produits de préservation du bois et matériaux dérivés soumises à enregistrement au titre de la rubrique n° 2415 de la nomenclature des installations classées pour la protection de l'environnement.\n",
      "Le présent arrêté fixe les prescriptions applicables aux installations de mise en œuvre de produits de préservation du bois et matériaux dérivés soumises à enregistrement au titre de la rubrique n° 2415 de la nomenclature des installations classées pour la protection de l'environnement.\n"
     ]
    }
   ],
   "source": [
    "# test decode \n",
    "print(sp.decode_pieces(pieces))\n",
    "print(sp.decode_ids(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juritok_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
